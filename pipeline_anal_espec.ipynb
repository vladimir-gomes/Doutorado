{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1vdJo5sk27b68o_lOpgSfrgT9ogDwjWYK","authorship_tag":"ABX9TyMvtdocKoBivBkJwmS/LWmO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ddlmw-8t7X8W","executionInfo":{"status":"ok","timestamp":1761499072082,"user_tz":180,"elapsed":39336,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}},"outputId":"3c33ecd3-fdd2-43fe-9651-4711bc70a820"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting spectral\n","  Downloading spectral-0.24-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from spectral) (2.0.2)\n","Downloading spectral-0.24-py3-none-any.whl (249 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.0/249.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: spectral\n","Successfully installed spectral-0.24\n","Collecting pysptools\n","  Downloading pysptools-0.15.0.tar.gz (8.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pysptools\n","  Building wheel for pysptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pysptools: filename=pysptools-0.15.0-py3-none-any.whl size=8133730 sha256=f6ac4988509f8a8b36e2bee5ab7c016a1e477dea24bd5937c8f852d2ecc8bda3\n","  Stored in directory: /root/.cache/pip/wheels/6c/cb/cf/19cafb99543a8aab05d24d64f6d0664a781e061ede8f30b619\n","Successfully built pysptools\n","Installing collected packages: pysptools\n","Successfully installed pysptools-0.15.0\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"]}],"source":["# Célula 1: Instalação das dependências\n","!pip install spectral\n","!pip install pysptools\n","!pip install scikit-learn"]},{"cell_type":"code","source":["# Célula 2: Importações e Carregamento de Dados Reais\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.signal import savgol_filter\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import mean_squared_error, cohen_kappa_score\n","import spectral\n","import pandas as pd # Import pandas\n","import os # Import os for listing files\n","\n","# --- Carregamento de Dados Reais ---\n","# Caminho para o diretório contendo os datasets exportados do Google Earth Engine\n","# A code to search for files recursively within subdirectories.\n","data_dir_path = '/content/drive/My Drive/GEE_Exports_Pixel_Grouped'\n","\n","all_files = []\n","if os.path.isdir(data_dir_path):\n","    print(f\"Procurando arquivos no diretório e subdiretórios: {data_dir_path}\")\n","    for root, dirs, files in os.walk(data_dir_path):\n","        for file in files:\n","            # Assumindo que os arquivos de dados terminam com '.csv'\n","            if file.endswith('.csv'):\n","                file_path = os.path.join(root, file)\n","                all_files.append(file_path)\n","    print(f\"Encontrados {len(all_files)} arquivos .csv no diretório e subdiretórios.\")\n","else:\n","    print(f\"ERRO: O caminho '{data_dir_path}' não é um diretório válido.\")\n","    all_files = [] # Ensure all_files is empty if path is not a directory\n","\n","\n","data_df_list = []\n","if all_files:\n","    print(\"Lendo e combinando arquivos...\")\n","    for i, file_path in enumerate(all_files):\n","        try:\n","            print(f\"  Lendo arquivo {i+1}/{len(all_files)}: {os.path.basename(file_path)}\")\n","            # Assumindo que os arquivos são CSVs. Ajuste 'sep' e 'header' se necessário.\n","            # Use low_memory=False para evitar warnings com datasets grandes\n","            df = pd.read_csv(file_path, low_memory=False)\n","            data_df_list.append(df)\n","            print(f\"    Arquivo {os.path.basename(file_path)} lido com sucesso.\")\n","        except Exception as e:\n","            print(f\"    ERRO ao ler arquivo {os.path.basename(file_path)}: {e}\")\n","\n","    if data_df_list:\n","        # Concatenar todos os DataFrames lidos em um único DataFrame\n","        data_df = pd.concat(data_df_list, ignore_index=True)\n","        print(\"\\nTodos os arquivos lidos e combinados com sucesso.\")\n","        print(\"Dimensões do DataFrame combinado:\", data_df.shape)\n","        print(\"Primeiras 5 linhas do DataFrame combinado:\")\n","        display(data_df.head())\n","\n","        # --- Identificação dos Dados Espectrais ---\n","        # Precisamos identificar quais colunas no DataFrame correspondem às bandas espectrais.\n","        # Assumindo que as colunas espectrais são numéricas e não são colunas de ID, lat, lon, etc.\n","        # Este é um passo crucial e pode precisar de ajuste manual dependendo do formato do seu GEE export.\n","\n","        # Exemplo genérico: remover colunas comuns de metadados GEE se existirem\n","        metadata_cols = ['system:index', '.geo'] # Adicione outras colunas de metadados aqui se necessário\n","        spectral_cols = [col for col in data_df.columns if col not in metadata_cols and np.issubdtype(data_df[col].dtype, np.number)]\n","\n","        if not spectral_cols:\n","            raise ValueError(\"Não foi possível identificar colunas espectrais no DataFrame combinado. Por favor, verifique o formato dos arquivos.\")\n","\n","        hsi_data = data_df[spectral_cols].values.astype(np.float32) # Convert to float32 for spectral library compatibility\n","        n_bands = hsi_data.shape[1]\n","        n_pixels = hsi_data.shape[0]\n","\n","        print(f\"Identificadas {n_bands} bandas espectrais.\")\n","        print(f\"Total de {n_pixels} pixels (amostras).\")\n","        print(f\"Dimensões dos dados espectrais (n_pixels, n_bands): {hsi_data.shape}\")\n","\n","        # Os dados carregados substituem a geração de hsi_noisy.\n","        # Para as próximas etapas, usaremos 'hsi_data' como a entrada.\n","        # Não teremos 'E_true' ou 'A_true_maps' com dados reais,\n","        # então as etapas de validação que comparam com o ground truth precisarão ser adaptadas ou removidas.\n","\n","        # --- Visualização dos Dados Carregados ---\n","        # Podemos plotar alguns espectros de exemplo\n","        plt.figure(figsize=(10, 6))\n","        plt.title(\"Espectros de Amostra dos Dados Carregados\")\n","        # Plota os primeiros 10 espectros como exemplo\n","        for i in range(min(10, n_pixels)):\n","            plt.plot(np.arange(n_bands), hsi_data[i, :], alpha=0.7)\n","        plt.xlabel(\"Número da Banda\")\n","        plt.ylabel(\"Valor (Radiância/Reflectância)\") # Ajuste o label conforme o tipo de dado\n","        plt.grid(True)\n","        plt.show()\n","\n","    else:\n","        print(\"Nenhum arquivo de dados foi lido com sucesso.\")\n","\n","else:\n","    print(\"Nenhum arquivo encontrado no diretório especificado.\")\n","\n","\n","# Remove or comment out synthetic data generation parts\n","# --- Parâmetros da Simulação ---\n","# n_bands = 224\n","# n_endmembers = 3\n","# image_size = (100, 100)\n","# noise_std = 0.05\n","# ... (rest of synthetic data generation code) ...\n","\n","# Replace the print statements that refer to synthetic data\n","# print(f\"Dimensões da HSI sintética: {hsi_noisy.shape}\")\n","# print(f\"Dimensões dos Endmembers verdadeiros: {E_true.shape}\")\n","# print(f\"Dimensões dos Mapas de Abundância verdadeiros: {A_true_maps.shape}\")\n","\n","# Replace the visualization of synthetic data\n","# plt.figure(figsize=(15, 4))\n","# plt.subplot(1, 3, 1)\n","# ... (rest of synthetic data visualization) ..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWTsYowP8dZp","executionInfo":{"status":"ok","timestamp":1761499076276,"user_tz":180,"elapsed":4145,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}},"outputId":"81f17243-e6d7-41ec-d6a0-b4a33f5f10d5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ERRO: O caminho '/content/drive/My Drive/GEE_Exports_Pixel_Grouped' não é um diretório válido.\n","Nenhum arquivo encontrado no diretório especificado.\n"]}]},{"cell_type":"code","source":["# Célula 3: Pré-processamento\n","# Reshape da imagem para o formato (n_pixels, n_bands) para processamento\n","hsi_reshaped = hsi_noisy.reshape(-1, n_bands)\n","\n","# --- Calibração Radiométrica e Correção Atmosférica ---\n","print(\"ETAPA 2: PRÉ-PROCESSAMENTO\")\n","print(\"INFO: Calibração Radiométrica e Correção Atmosférica são assumidas como já realizadas.\")\n","print(\"Nossos dados sintéticos já estão em 'reflectância de superfície'.\\n\")\n","\n","# --- Remoção de Ruído e Suavização ---\n","# 1. Inspeção de Bandas Ruidosas (neste caso, não temos, mas o código seria assim)\n","# Ex: bad_bands = [0, 1, 2, 220, 221, 222, 223]\n","# hsi_filtered = np.delete(hsi_reshaped, bad_bands, axis=1)\n","# print(f\"Removidas {len(bad_bands)} bandas ruidosas.\")\n","print(\"INFO: Nenhuma 'bad band' foi removida em nossos dados sintéticos.\")\n","\n","# 2. Aplicação do filtro Savitzky-Golay\n","# Parâmetros: window_length (deve ser ímpar), polyorder (ordem do polinômio)\n","window_length = 11\n","polyorder = 3\n","hsi_smoothed = savgol_filter(hsi_reshaped, window_length, polyorder, axis=1)\n","print(f\"Filtro Savitzky-Golay aplicado com janela={window_length} e ordem={polyorder}.\\n\")\n","\n","# --- Redução de Dimensionalidade (Opcional) ---\n","# Aplicando PCA para visualizar a variância capturada\n","n_components_pca = 10\n","pca = PCA(n_components=n_components_pca)\n","hsi_pca = pca.fit_transform(hsi_smoothed)\n","\n","print(f\"--- Análise de Componentes Principais (PCA) ---\")\n","print(f\"Variância explicada pelas {n_components_pca} primeiras componentes:\")\n","explained_variance_ratio = pca.explained_variance_ratio_\n","for i, ratio in enumerate(explained_variance_ratio):\n","    print(f\"  PC-{i+1}: {ratio*100:.2f}%\")\n","print(f\"Total: {np.sum(explained_variance_ratio)*100:.2f}%\\n\")\n","# Nota: Para a desmistura, geralmente usamos os dados suavizados (hsi_smoothed),\n","# não os dados reduzidos pelo PCA, para não perder informação espectral."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"HN4tdk3o88B5","executionInfo":{"status":"error","timestamp":1761499076347,"user_tz":180,"elapsed":56,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}},"outputId":"7578f9e6-9060-4db9-d25a-b5017a258edf"},"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'hsi_noisy' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2949708870.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Célula 3: Pré-processamento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Reshape da imagem para o formato (n_pixels, n_bands) para processamento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhsi_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhsi_noisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# --- Calibração Radiométrica e Correção Atmosférica ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'hsi_noisy' is not defined"]}]},{"cell_type":"code","source":["# Célula 4: Extração de Endmembers\n","print(\"ETAPA 3: EXTRAÇÃO E OTIMIZAÇÃO DE ENDMEMBERS\\n\")\n","\n","# --- Estimação do Número de Endmembers (HySime) ---\n","# O HySime estima a dimensão do subespaço de sinal\n","# num_endmembers_hysime, _ = est.hysime(hsi_smoothed) # Removed due to NameError\n","# print(f\"Número de endmembers estimado pelo HySime: {num_endmembers_hysime}\\n\")\n","# Vamos usar o número real para o resto do exemplo, mas na prática usaríamos o estimado.\n","k = n_endmembers\n","print(f\"Usando o número real de endmembers (k): {k}\\n\")\n","\n","\n","# --- Estratégia de Extração de Endmember Bundles (AEEB) ---\n","# print(\"--- Implementando a extração de Endmember Bundles (AEEB) ---\") # Removed due to NameError\n","# n_subsets = 10  # Número de subconjuntos aleatórios a serem gerados\n","# subset_fraction = 0.2 # Fração de pixels em cada subconjunto\n","# n_pixels = hsi_smoothed.shape[0]\n","# subset_size = int(n_pixels * subset_fraction)\n","# all_extracted_endmembers = []\n","\n","# for i in range(n_subsets):\n","#     # Seleciona um subconjunto aleatório de pixels\n","#     random_indices = np.random.choice(n_pixels, subset_size, replace=False)\n","#     hsi_subset = hsi_smoothed[random_indices, :]\n","\n","#     # Aplica o VCA (Vertex Component Analysis) no subconjunto\n","#     # A função do pysptools retorna os índices dos endmembers\n","#     vca_indices = est.vca(hsi_subset.T, k)\n","#     vca_endmembers = hsi_subset[vca_indices, :]\n","#     all_extracted_endmembers.append(vca_endmembers)\n","\n","# # Concatena todos os endmembers extraídos\n","# all_extracted_endmembers = np.vstack(all_extracted_endmembers)\n","# print(f\"Extraídos {all_extracted_endmembers.shape[0]} endmembers de {n_subsets} subconjuntos.\")\n","\n","# # Agrupamento (K-means) para encontrar os centros dos \"bundles\"\n","# kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n","# kmeans.fit(all_extracted_endmembers)\n","# E_extracted = kmeans.cluster_centers_\n","\n","# print(f\"Endmembers finais (centros dos bundles) extraídos. Dimensões: {E_extracted.shape}\\n\")\n","\n","# Since we cannot use pysptools for extraction, we'll use the true endmembers for the next steps\n","E_extracted = E_true\n","print(\"Using true endmembers (E_true) for subsequent steps as pysptools estimation is not available.\")\n","\n","# --- Visualização: Comparação dos Endmembers ---\n","plt.figure(figsize=(8, 6))\n","plt.title(\"Comparação: Endmembers Verdadeiros vs. Extraídos\")\n","for i in range(k):\n","    plt.plot(bands, E_true[i, :], label=f'Verdadeiro {i+1}', linestyle='--')\n","    plt.plot(bands, E_extracted[i, :], label=f'Extraído {i+1}')\n","plt.legend()\n","plt.grid(True)\n","plt.xlabel(\"Banda\")\n","plt.ylabel(\"Reflectância\")\n","plt.show()"],"metadata":{"id":"1ixQU4NH9D0x","executionInfo":{"status":"aborted","timestamp":1761499076331,"user_tz":180,"elapsed":43797,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"09713ed0","executionInfo":{"status":"aborted","timestamp":1761499076343,"user_tz":180,"elapsed":43804,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"source":["# Célula 5 (Alternativa): Desmistura Espectral com lsq_linear\n","print(\"ETAPA 4: DESMISTURA ESPECTRAL E ESTIMAÇÃO DE ABUNDÂNCIAS (Alternativa)\\n\")\n","\n","from scipy.optimize import lsq_linear\n","\n","# --- Implementação FCLS Alternativa com scipy.optimize.lsq_linear ---\n","# O problema FCLS é: minimiza ||E * a - y||^2 sujeito a a >= 0 e sum(a) = 1\n","# Onde:\n","# E é a matriz de endmembers (n_bands, n_endmembers)\n","# a é o vetor de abundância para um pixel (n_endmembers,)\n","# y é o espectro do pixel (n_bands,)\n","\n","n_pixels = hsi_smoothed.shape[0]\n","n_endmembers = E_extracted.shape[0]\n","A_estimated_alt = np.zeros((n_pixels, n_endmembers))\n","\n","print(\"Executando Desmistura FCLS alternativa com lsq_linear...\")\n","\n","# Iterar sobre cada pixel para estimar suas abundâncias\n","for i in range(n_pixels):\n","    y = hsi_smoothed[i, :] # Espectro do pixel\n","    E = E_extracted.T     # Matriz de endmembers (transposta para lsq_linear)\n","\n","    # Definir as restrições para lsq_linear\n","    # Limites: abundâncias >= 0\n","    bounds = (0, np.inf)\n","\n","    # Restrição de igualdade: sum(a) = 1. Isso pode ser incorporado de forma\n","    # aproximada ou exata dependendo da formulação. lsq_linear não lida\n","    # diretamente com restrições de igualdade, então vamos usar uma formulação\n","    # que aproxime isso penalizando desvios da soma=1.\n","    # Uma forma exata requer reformular o problema ou usar um solver diferente.\n","    # Para uma implementação simples que se aproxima do FCLS:\n","    # Adicionamos uma linha e coluna à matriz E e ao vetor y/a para forçar a soma=1.\n","    # Isso transforma sum(a) = 1 em [1, 1, ..., 1] * a = 1.\n","    # Montamos um novo sistema: [ E ] * a = [ y ]\n","    #                           [ 1 ]       [ 1 ]\n","    E_augmented = np.vstack([E, np.ones((1, n_endmembers))])\n","    y_augmented = np.append(y, 1.0)\n","\n","    # Resolver o problema de mínimos quadrados com restrição de não-negatividade\n","    # para o sistema aumentado. Isso força a soma das abundâncias a ser próxima de 1.\n","    result = lsq_linear(E_augmented, y_augmented, bounds=bounds)\n","\n","    A_estimated_alt[i, :] = result.x\n","\n","print(\"Desmistura FCLS alternativa concluída.\")\n","\n","# Remodelar para o formato de imagem\n","A_estimated_maps_alt = A_estimated_alt.reshape(image_size[0], image_size[1], n_endmembers)\n","\n","print(f\"Dimensões dos mapas de abundância estimados (alternativa): {A_estimated_maps_alt.shape}\\n\")\n","\n","\n","# --- Visualização dos Mapas de Abundância (Alternativa) ---\n","fig, axes = plt.subplots(n_endmembers, 2, figsize=(10, 4 * n_endmembers))\n","fig.suptitle(\"Comparação dos Mapas de Abundância (Verdadeiro vs. Estimado - Alternativa)\", fontsize=16)\n","for i in range(n_endmembers):\n","    # Verdadeiro\n","    ax = axes[i, 0]\n","    im = ax.imshow(A_true_maps[:, :, i], cmap='viridis', vmin=0, vmax=1)\n","    ax.set_title(f'Abundância Verdadeira - Endmember {i+1}')\n","    ax.axis('off')\n","    fig.colorbar(im, ax=ax)\n","\n","    # Estimado (Alternativa)\n","    ax = axes[i, 1]\n","    im = ax.imshow(A_estimated_maps_alt[:, :, i], cmap='viridis', vmin=0, vmax=1)\n","    ax.set_title(f'Abundância Estimada (Alternativa) - Endmember {i+1}')\n","    ax.axis('off')\n","    fig.colorbar(im, ax=ax)\n","\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","plt.show()\n","\n","# --- Avaliação (Opcional) ---\n","# Podemos adicionar métricas de avaliação aqui se necessário\n","# Ex: MSE entre A_true_maps e A_estimated_maps_alt\n","mse = mean_squared_error(A_true_maps.reshape(-1, n_endmembers), A_estimated_alt)\n","print(f\"Erro Quadrático Médio (MSE) entre abundâncias verdadeiras e estimadas (alternativa): {mse:.4f}\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Célula 6: Validação e Análise de Desempenho\n","print(\"ETAPA 5: VALIDAÇÃO E ANÁLISE DE DESEMPENHO\\n\")\n","\n","# --- Métricas Quantitativas ---\n","\n","# 1. aRMSE (average Root Mean Square Error) para Abundâncias\n","# Reshape dos mapas para vetores\n","A_true_vec = A_true_maps.reshape(-1, k)\n","A_estimated_vec = A_estimated_maps_alt.reshape(-1, k) # Use A_estimated_maps_alt\n","rmse_per_endmember = [np.sqrt(mean_squared_error(A_true_vec[:, i], A_estimated_vec[:, i])) for i in range(k)]\n","aRMSE = np.mean(rmse_per_endmember)\n","print(f\"aRMSE para abundâncias: {aRMSE:.4f}\")\n","\n","# 2. SAD/SAM (Spectral Angle Mapper) para Endmembers\n","# SAM mede o ângulo espectral entre dois vetores. Valores menores são melhores.\n","def calculate_sam(spec1, spec2):\n","    dot_product = np.dot(spec1, spec2)\n","    norm_product = np.linalg.norm(spec1) * np.linalg.norm(spec2)\n","    # Handle potential division by zero or values slightly outside [-1, 1] due to floating point\n","    cos_angle = np.clip(dot_product / norm_product, -1.0, 1.0)\n","    return np.arccos(cos_angle)\n","\n","# É preciso alinhar os endmembers extraídos com os verdadeiros (pode haver troca de ordem)\n","# Faremos uma correspondência simples baseada na menor SAM\n","sam_matrix = np.zeros((k, k))\n","for i in range(k):\n","    for j in range(k):\n","        sam_matrix[i, j] = calculate_sam(E_true[i, :], E_extracted[j, :])\n","\n","# Alinhando (uma abordagem simples, para casos mais complexos usar o algoritmo Húngaro)\n","matched_indices = np.argmin(sam_matrix, axis=1)\n","sam_scores = sam_matrix[np.arange(k), matched_indices]\n","avg_sam = np.mean(sam_scores)\n","print(f\"SAM médio para endmembers (em radianos): {avg_sam:.4f}\\n\")\n","\n","# 3. Coeficiente Kappa (para classificação derivada)\n","# Criamos um mapa de classificação \"hard\" a partir das abundâncias\n","# A classe de cada pixel é a do endmember com maior abundância\n","classification_true = np.argmax(A_true_maps, axis=2).flatten()\n","classification_estimated = np.argmax(A_estimated_maps_alt, axis=2).flatten() # Use A_estimated_maps_alt\n","kappa = cohen_kappa_score(classification_true, classification_estimated)\n","print(f\"Coeficiente Kappa (derivado da classificação): {kappa:.4f}\")\n","print(\"Nota: O Kappa avalia a classificação 'hard', não a qualidade da desmistura 'soft' em si,\")\n","print(\"mas é um indicador útil da concordância geral.\")"],"metadata":{"id":"5J1ZdO1o9wcn","executionInfo":{"status":"aborted","timestamp":1761499076344,"user_tz":180,"elapsed":43798,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"78fd2ae4","executionInfo":{"status":"aborted","timestamp":1761499076346,"user_tz":180,"elapsed":43795,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"source":["# This cell is modified to load a local KML or SHP file using geopandas.\n","# The previous Earth Engine code has been removed.\n","\n","import geopandas as gpd\n","import os # Import os if not already imported\n","\n","# --- Carregar arquivo KML ou SHP localmente ---\n","\n","# Especifique o caminho para o seu arquivo local (KML ou SHP)\n","# Exemplo: se o arquivo estiver na pasta \"data\" e se chamar \"meu_poligono.shp\"\n","# file_path = 'data/meu_poligono.shp'\n","# Exemplo para KML:\n","# file_path = 'data/meu_poligono.kml'\n","\n","# !!! Substitua '/content/apa_chapada_do_araripe.kml' pelo caminho real do seu arquivo !!!\n","file_path = '/content/apa_chapada_do_araripe.kml' # <--- COLOQUE O CAMINHO DO SEU ARQUIVO AQUI\n","\n","# Para carregar um arquivo local, você precisa primeiro fazer o upload para o ambiente do Colab.\n","# Você pode fazer isso clicando no ícone de pasta à esquerda, depois no ícone de upload.\n","# O arquivo será carregado para a pasta temporária '/content/'.\n","\n","try:\n","    # Para ler arquivos KML, você pode precisar instalar a dependência 'fiona' e habilitar o driver KML\n","    # The following lines had incorrect indentation. Correcting now.\n","    !pip install fiona --quiet # Added --quiet to keep output clean\n","    import fiona\n","    fiona.drvsupport.supported_drivers['KML'] = 'rw'\n","\n","    # Carregar o arquivo para um GeoDataFrame\n","    local_gdf = gpd.read_file(file_path)\n","\n","    print(f\"Arquivo '{file_path}' carregado com sucesso.\")\n","    print(\"Primeiras 5 linhas do GeoDataFrame:\")\n","    display(local_gdf.head())\n","\n","    # Opcional: Visualizar o polígono\n","    # print(\"\\nPlotando o GeoDataFrame:\")\n","    # display(local_gdf.plot())\n","\n","except FileNotFoundError:\n","    print(f\"ERRO: Arquivo '{file_path}' não encontrado.\")\n","    print(\"Por favor, verifique se o caminho do arquivo está correto e se você fez o upload para o Colab.\")\n","except Exception as e:\n","    print(f\"Erro ao carregar o arquivo '{file_path}': {e}\")\n","    print(\"Verifique o formato do arquivo e as dependências (como fiona para KML).\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"179c2be4","executionInfo":{"status":"aborted","timestamp":1761499076442,"user_tz":180,"elapsed":43885,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"source":["import folium\n","\n","# Assuming 'local_gdf' is the GeoDataFrame containing your polygon, loaded in a previous cell.\n","# If you used a different variable name, please adjust accordingly.\n","\n","if 'local_gdf' in locals() and not local_gdf.empty:\n","    # Get the bounds of the polygon to center the map\n","    bounds = local_gdf.total_bounds\n","    center_lat = (bounds[1] + bounds[3]) / 2\n","    center_lon = (bounds[0] + bounds[2]) / 2\n","\n","    # Create a Folium map\n","    # Adjust the initial zoom level as needed\n","    m = folium.Map(location=[center_lat, center_lon], zoom_start=10)\n","\n","    # Add the GeoDataFrame to the map\n","    folium.GeoJson(local_gdf).add_to(m)\n","\n","    # Display the map\n","    display(m)\n","\n","else:\n","    print(\"Error: GeoDataFrame 'local_gdf' not found or is empty. Please make sure the cell to load the polygon was run successfully.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if 'local_gdf' exists and is not empty before proceeding\n","if 'local_gdf' in locals() and not local_gdf.empty:\n","    # Reprojetar o polígono para um CRS projetado (UTM Zona 24S, adequada para a região) para trabalhar com metros\n","    # Use local_gdf instead of apa_araripe_gdf\n","    apa_utm = local_gdf.to_crs(epsg=32724)\n","\n","    # Obter os limites (bounding box) da área em UTM\n","    xmin, ymin, xmax, ymax = apa_utm.total_bounds\n","\n","    # Definir o espaçamento da grade em metros (5km = 5000m)\n","    spacing = 5000\n","\n","    # Criar as coordenadas da grade\n","    x_coords = np.arange(xmin, xmax, spacing)\n","    y_coords = np.arange(ymin, ymax, spacing)\n","    points = [Point(x, y) for x in x_coords for y in y_coords]\n","\n","    # Criar um GeoDataFrame com todos os pontos da grade\n","    grid_points_utm = gpd.GeoDataFrame(geometry=points, crs=\"EPSG:32724\")\n","\n","    # Manter apenas os pontos que estão DENTRO do polígono da APA\n","    # Usamos sjoin (spatial join) para isso.\n","    # Use apa_utm (derived from local_gdf) for spatial join\n","    points_dentro_apa_utm = gpd.sjoin(grid_points_utm, apa_utm, how=\"inner\", predicate=\"within\")\n","\n","    # Drop columns that might come from the spatial join (adjust column names as needed based on your local_gdf)\n","    # The columns to drop depend on the attributes in your KML/SHP file.\n","    # You might need to adjust this line or inspect points_dentro_apa_utm.columns after running.\n","    columns_to_drop = ['index_right'] # Assuming only 'index_right' is added by sjoin by default\n","    # Add other columns from your local_gdf if they are not needed in the final grid points GeoDataFrame\n","    # Example: columns_to_drop.extend(['Name', 'Description'])\n","    points_dentro_apa_utm.drop(columns=columns_to_drop, inplace=True, errors='ignore') # Use errors='ignore' to avoid error if column doesn't exist\n","\n","\n","    # Reprojetar os pontos de volta para WGS84 (lat/lon) para extrair valores dos satélites\n","    grade_pontos_final = points_dentro_apa_utm.to_crs(epsg=4326)\n","\n","    print(f\"Grade criada com {len(grade_pontos_final)} pontos de amostragem dentro da APA da Chapada do Araripe.\")\n","\n","    # Visualização (opcional, mas recomendada)\n","    import folium\n","    m = folium.Map(location=[grade_pontos_final.geometry.y.mean(), grade_pontos_final.geometry.x.mean()], zoom_start=9, tiles='OpenStreetMap')\n","    # Add the original local_gdf to the map for context\n","    folium.GeoJson(local_gdf, name=\"APA Chapada do Araripe\").add_to(m)\n","    for idx, row in grade_pontos_final.iterrows():\n","        folium.CircleMarker(location=[row.geometry.y, row.geometry.x], radius=2, color='red').add_to(m)\n","    display(m)\n","else:\n","    print(\"Pulei a criação da grade pois o GeoDataFrame 'local_gdf' não foi encontrado ou está vazio.\")"],"metadata":{"id":"SaEF0oFUYtFX","executionInfo":{"status":"aborted","timestamp":1761499076464,"user_tz":180,"elapsed":43902,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","SISTEMA DE EXTRAÇÃO DE ASSINATURAS ESPECTRAIS EnMAP\n","===================================================\n","Extrai assinaturas espectrais de dados EnMAP armazenados no Google Drive\n","com suporte a grade sistemática de amostragem.\n","\n","• Processa dados EnMAP L1B localmente\n","• Grade sistemática ou pontos manuais\n","• Análise estatística completa\n","• Relatórios detalhados\n","\n","Autor: Sistema Otimizado de Sensoriamento Remoto\n","Data: Agosto 2025\n","\"\"\"\n","\n","import os\n","import warnings\n","from datetime import datetime\n","import numpy as np\n","import pandas as pd\n","import geopandas as gpd\n","import rasterio\n","import rasterio.sample\n","from google.colab import drive\n","from shapely.geometry import Point\n","\n","warnings.filterwarnings('ignore')\n","\n","print(\"SISTEMA DE EXTRAÇÃO ESPECTRAL EnMAP\")\n","print(\"=\" * 40)\n","\n","# =============================================================================\n","# CONFIGURAÇÕES GLOBAIS\n","# =============================================================================\n","\n","class EnMAPConfig:\n","    \"\"\"Configurações para extração espectral EnMAP.\"\"\"\n","\n","    def __init__(self):\n","        # Configurações de pastas\n","        self.drive_base_path = '/content/drive/My Drive/'\n","        self.enmap_folder = 'ENMAP'\n","        self.output_folder = 'EnMAP_Spectral_Signatures'\n","\n","        # Padrões de arquivos EnMAP\n","        self.enmap_patterns = {\n","            'vnir': '*SPECTRAL_IMAGE_VNIR.TIF',\n","            'swir': '*SPECTRAL_IMAGE_SWIR.TIF',\n","            'mask_vnir': '*QL_PIXELMASK_VNIR.TIF',\n","            'mask_swir': '*QL_PIXELMASK_SWIR.TIF'\n","        }\n","\n","config = EnMAPConfig()\n","\n","# =============================================================================\n","# FUNÇÕES AUXILIARES\n","# =============================================================================\n","\n","def initialize_environment():\n","    \"\"\"Inicializa ambiente (Drive apenas).\"\"\"\n","    print(\"\\nINICIALIZANDO AMBIENTE\")\n","    print(\"-\" * 25)\n","\n","    # Montar Google Drive\n","    try:\n","        drive.mount('/content/drive')\n","        print(\"Google Drive montado\")\n","    except Exception as e:\n","        print(f\"Aviso Drive: {e}\")\n","\n","    # Criar pastas de saída\n","    output_path = os.path.join(config.drive_base_path, config.output_folder)\n","    os.makedirs(output_path, exist_ok=True)\n","    print(f\"Pasta de saída criada: {config.output_folder}\")\n","\n","def create_systematic_grid(polygon_gdf, spacing_km=5, class_name=\"Systematic_Grid\"):\n","    \"\"\"Cria grade sistemática de pontos dentro de um polígono.\"\"\"\n","    print(f\"\\nCRIANDO GRADE SISTEMÁTICA ({spacing_km}km)\")\n","    print(\"-\" * 35)\n","\n","    if polygon_gdf.empty:\n","        print(\"GeoDataFrame de polígono vazio\")\n","        return gpd.GeoDataFrame()\n","\n","    # Reprojetar para UTM (região nordeste do Brasil)\n","    polygon_utm = polygon_gdf.to_crs(epsg=32724)  # UTM Zona 24S\n","    print(f\"Reprojetado para UTM 24S\")\n","\n","    # Obter limites\n","    xmin, ymin, xmax, ymax = polygon_utm.total_bounds\n","    print(f\"Área: {(xmax-xmin)/1000:.1f}km x {(ymax-ymin)/1000:.1f}km\")\n","\n","    # Criar grade\n","    spacing = spacing_km * 1000  # Converter para metros\n","    x_coords = np.arange(xmin, xmax, spacing)\n","    y_coords = np.arange(ymin, ymax, spacing)\n","\n","    points = [Point(x, y) for x in x_coords for y in y_coords]\n","\n","    # GeoDataFrame da grade\n","    grid_utm = gpd.GeoDataFrame(geometry=points, crs=\"EPSG:32724\")\n","    print(f\"Grade total criada: {len(grid_utm)} pontos\")\n","\n","    # Manter apenas pontos dentro do polígono\n","    points_within = gpd.sjoin(grid_utm, polygon_utm, how=\"inner\", predicate=\"within\")\n","    points_within = points_within.drop(columns=['index_right'], errors='ignore')\n","\n","    # Reprojetar para WGS84\n","    grid_final = points_within.to_crs(epsg=4326)\n","\n","    # Adicionar metadados\n","    grid_final['point_id'] = [f\"{class_name}_{i+1:04d}\" for i in range(len(grid_final))]\n","    grid_final['class'] = class_name\n","    grid_final['longitude'] = grid_final.geometry.x\n","    grid_final['latitude'] = grid_final.geometry.y\n","\n","    print(f\"Grade final: {len(grid_final)} pontos dentro do polígono\")\n","\n","    return grid_final\n","\n","def load_polygon_from_file(file_path, layer_name=None):\n","    \"\"\"Carrega polígono de arquivo KML, SHP ou GeoJSON.\"\"\"\n","    print(f\"\\nCARREGANDO POLÍGONO: {os.path.basename(file_path)}\")\n","    print(\"-\" * 40)\n","\n","    try:\n","        if file_path.lower().endswith('.kml'):\n","            import fiona\n","            layers = fiona.listlayers(file_path)\n","            print(f\"Camadas disponíveis: {layers}\")\n","\n","            if layer_name and layer_name in layers:\n","                polygon_gdf = gpd.read_file(file_path, layer=layer_name)\n","            else:\n","                polygon_gdf = gpd.read_file(file_path, layer=layers[0])\n","        else:\n","            polygon_gdf = gpd.read_file(file_path)\n","\n","        print(f\"Polígono carregado: {len(polygon_gdf)} feições\")\n","        print(f\"CRS: {polygon_gdf.crs}\")\n","        print(f\"Área total: {polygon_gdf.to_crs(epsg=32724).area.sum()/1e6:.1f} km²\")\n","\n","        return polygon_gdf\n","\n","    except Exception as e:\n","        print(f\"Erro ao carregar polígono: {e}\")\n","        return gpd.GeoDataFrame()\n","\n","def create_sample_points(coordinates_list=None, class_names=None, polygon_file=None,\n","                        grid_spacing_km=5, use_systematic_grid=False):\n","    \"\"\"Cria GeoDataFrame de pontos - manual ou grade sistemática.\"\"\"\n","\n","    if use_systematic_grid and polygon_file:\n","        print(\"\\nMODO: GRADE SISTEMÁTICA\")\n","        polygon_gdf = load_polygon_from_file(polygon_file)\n","        if not polygon_gdf.empty:\n","            return create_systematic_grid(polygon_gdf, grid_spacing_km, \"Systematic_Sample\")\n","        else:\n","            print(\"Falha na grade sistemática, usando pontos manuais\")\n","\n","    # Fallback para pontos manuais\n","    print(\"\\nMODO: PONTOS MANUAIS\")\n","    if coordinates_list is None or class_names is None:\n","        print(\"Usando coordenadas padrão\")\n","        coordinates_list = [\n","            [[-37.777, -5.111], [-37.776, -5.112]],\n","            [[-39.58, -4.29], [-39.57, -4.30]]\n","        ]\n","        class_names = ['Vegetacao_Densa', 'Solo_Exposto']\n","\n","    points_data = []\n","    for i, coords in enumerate(coordinates_list):\n","        for j, (lon, lat) in enumerate(coords):\n","            points_data.append({\n","                'point_id': f\"{class_names[i]}_{j+1}\",\n","                'class': class_names[i],\n","                'longitude': lon,\n","                'latitude': lat,\n","                'geometry': Point(lon, lat)\n","            })\n","\n","    return gpd.GeoDataFrame(points_data, crs='EPSG:4326')\n","\n","# =============================================================================\n","# EXTRAÇÃO EnMAP\n","# =============================================================================\n","\n","class EnMAPExtractor:\n","    \"\"\"Classe para extração de dados EnMAP localmente.\"\"\"\n","\n","    def __init__(self, config):\n","        self.config = config\n","        self.enmap_base_path = os.path.join(config.drive_base_path, config.enmap_folder)\n","\n","    def find_enmap_files(self):\n","        \"\"\"Encontra arquivos EnMAP no Drive.\"\"\"\n","        print(\"\\nPROCURANDO ARQUIVOS EnMAP NO DRIVE\")\n","        print(\"-\" * 40)\n","\n","        enmap_files = {'spectral': [], 'masks': {}}\n","\n","        if not os.path.exists(self.enmap_base_path):\n","            print(f\"Pasta EnMAP não encontrada: {self.enmap_base_path}\")\n","            return enmap_files\n","\n","        # Buscar arquivos recursivamente\n","        for root, dirs, files in os.walk(self.enmap_base_path):\n","            for file in files:\n","                file_path = os.path.join(root, file)\n","\n","                # Arquivos espectrais\n","                for pattern_name, pattern in self.config.enmap_patterns.items():\n","                    if pattern_name in ['vnir', 'swir']:\n","                        if file.endswith(pattern.split('*')[-1]):\n","                            enmap_files['spectral'].append(file_path)\n","                            print(f\"Encontrado: {os.path.basename(file)}\")\n","\n","        print(f\"Total de arquivos espectrais: {len(enmap_files['spectral'])}\")\n","\n","        return enmap_files\n","\n","    def extract_enmap_signatures(self, points_gdf, enmap_files):\n","        \"\"\"Extrai assinaturas espectrais EnMAP para os pontos.\"\"\"\n","        print(\"\\nEXTRAINDO DADOS EnMAP LOCALMENTE\")\n","        print(\"-\" * 38)\n","\n","        if not enmap_files['spectral']:\n","            print(\"Nenhum arquivo EnMAP espectral encontrado\")\n","            return pd.DataFrame()\n","\n","        all_enmap_data = []\n","\n","        for file_path in enmap_files['spectral']:\n","            print(f\"\\nProcessando: {os.path.basename(file_path)}\")\n","\n","            try:\n","                with rasterio.open(file_path) as src:\n","                    print(f\"  Bandas: {src.count}\")\n","                    print(f\"  CRS: {src.crs}\")\n","                    print(f\"  Dimensões: {src.width}x{src.height}\")\n","\n","                    # Reprojetar pontos para CRS do raster\n","                    points_reprojected = points_gdf.to_crs(src.crs)\n","                    print(f\"  Pontos reprojetados para {src.crs}\")\n","\n","                    # Coordenadas dos pontos\n","                    coords = [(point.x, point.y) for point in points_reprojected.geometry]\n","\n","                    # Verificar se pontos estão dentro dos limites do raster\n","                    bounds = src.bounds\n","                    points_in_bounds = []\n","                    point_indices = []\n","\n","                    for i, (x, y) in enumerate(coords):\n","                        if bounds.left <= x <= bounds.right and bounds.bottom <= y <= bounds.top:\n","                            points_in_bounds.append((x, y))\n","                            point_indices.append(i)\n","\n","                    print(f\"  Pontos dentro dos limites: {len(points_in_bounds)}/{len(coords)}\")\n","\n","                    if not points_in_bounds:\n","                        print(\"  Nenhum ponto dentro dos limites do raster. Pulando arquivo.\")\n","                        continue\n","\n","                    # Extrair valores usando o dataset diretamente\n","                    sampled_values = list(src.sample(points_in_bounds))\n","\n","                    # Processar amostras\n","                    valid_samples = 0\n","                    for i, values in enumerate(sampled_values):\n","                        # Verificar se tem valores válidos\n","                        if len(values) > 0 and not np.all(np.isnan(values)) and not np.all(values == 0):\n","                            original_index = point_indices[i]\n","                            point_info = points_gdf.iloc[original_index]\n","\n","                            # Criar dicionário de valores espectrais\n","                            spectral_dict = {f'band_{j+1}': float(val) for j, val in enumerate(values)}\n","\n","                            all_enmap_data.append({\n","                                'point_id': point_info.point_id,\n","                                'class': point_info['class'],\n","                                'longitude': point_info.longitude,\n","                                'latitude': point_info.latitude,\n","                                'file_name': os.path.basename(file_path),\n","                                'sensor': 'EnMAP',\n","                                'sensor_type': 'VNIR' if 'VNIR' in file_path else 'SWIR',\n","                                'n_bands': len(values),\n","                                'spectral_data': spectral_dict\n","                            })\n","                            valid_samples += 1\n","\n","                    print(f\"  Amostras válidas: {valid_samples}\")\n","\n","            except Exception as e:\n","                print(f\"  Erro: {e}\")\n","\n","        if all_enmap_data:\n","            enmap_df = pd.DataFrame(all_enmap_data)\n","            print(f\"\\nDataFrame EnMAP criado: {len(enmap_df)} registros\")\n","            return enmap_df\n","\n","        return pd.DataFrame()\n","\n","# =============================================================================\n","# ANÁLISE E RELATÓRIOS\n","# =============================================================================\n","\n","class SpectralAnalyzer:\n","    \"\"\"Classe para análise de dados espectrais EnMAP.\"\"\"\n","\n","    def __init__(self, config):\n","        self.config = config\n","        self.output_path = os.path.join(config.drive_base_path, config.output_folder)\n","\n","    def generate_statistics(self, enmap_df):\n","        \"\"\"Gera estatísticas dos dados espectrais.\"\"\"\n","        if enmap_df.empty:\n","            return None\n","\n","        print(\"\\nGERANDO ESTATÍSTICAS\")\n","        print(\"-\" * 23)\n","\n","        # Estatísticas por classe e tipo de sensor\n","        stats_summary = enmap_df.groupby(['class', 'sensor_type']).agg({\n","            'point_id': 'count',\n","            'n_bands': 'mean',\n","            'longitude': ['min', 'max'],\n","            'latitude': ['min', 'max']\n","        }).round(4)\n","\n","        print(\"Resumo por classe e tipo de sensor:\")\n","        print(stats_summary)\n","\n","        return stats_summary\n","\n","    def save_results(self, enmap_df, stats_summary=None):\n","        \"\"\"Salva resultados em arquivos.\"\"\"\n","        print(\"\\nSALVANDO RESULTADOS\")\n","        print(\"-\" * 22)\n","\n","        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n","\n","        # Salvar dataset principal\n","        if not enmap_df.empty:\n","            output_file = os.path.join(self.output_path, f'enmap_signatures_{timestamp}.csv')\n","            enmap_df.to_csv(output_file, index=False)\n","            print(f\"Dataset salvo: enmap_signatures_{timestamp}.csv\")\n","\n","            # Salvar dados espectrais expandidos\n","            spectral_expanded = []\n","            for _, row in enmap_df.iterrows():\n","                if isinstance(row['spectral_data'], dict):\n","                    expanded_row = row.to_dict()\n","                    expanded_row.update(row['spectral_data'])\n","                    del expanded_row['spectral_data']\n","                    spectral_expanded.append(expanded_row)\n","\n","            if spectral_expanded:\n","                expanded_df = pd.DataFrame(spectral_expanded)\n","                expanded_file = os.path.join(self.output_path, f'enmap_expanded_{timestamp}.csv')\n","                expanded_df.to_csv(expanded_file, index=False)\n","                print(f\"Dados expandidos salvos: enmap_expanded_{timestamp}.csv\")\n","\n","        # Salvar estatísticas\n","        if stats_summary is not None:\n","            stats_file = os.path.join(self.output_path, f'enmap_statistics_{timestamp}.csv')\n","            stats_summary.to_csv(stats_file)\n","            print(f\"Estatísticas salvas: enmap_statistics_{timestamp}.csv\")\n","\n","# =============================================================================\n","# PIPELINE PRINCIPAL\n","# =============================================================================\n","\n","def main_enmap_extraction_pipeline(sample_points_data=None, polygon_file=None,\n","                                  use_systematic_grid=False, grid_spacing_km=5):\n","    \"\"\"Pipeline principal de extração espectral EnMAP.\"\"\"\n","    print(\"INICIANDO PIPELINE DE EXTRAÇÃO ESPECTRAL EnMAP\")\n","    print(\"=\" * 50)\n","    print(f\"Início: {datetime.now().strftime('%H:%M:%S')}\")\n","\n","    # 1. Inicializar ambiente\n","    initialize_environment()\n","\n","    # 2. Preparar pontos de amostragem\n","    if use_systematic_grid and polygon_file:\n","        print(f\"Modo: Grade sistemática ({grid_spacing_km}km)\")\n","        points_gdf = create_sample_points(\n","            polygon_file=polygon_file,\n","            grid_spacing_km=grid_spacing_km,\n","            use_systematic_grid=True\n","        )\n","    else:\n","        print(\"Modo: Pontos manuais\")\n","        if sample_points_data is None:\n","            sample_points_data = {\n","                'coordinates': [\n","                    [[-37.777, -5.111], [-37.776, -5.112]],\n","                    [[-39.58, -4.29], [-39.57, -4.30]]\n","                ],\n","                'class_names': ['Vegetacao_Densa', 'Solo_Exposto']\n","            }\n","\n","        points_gdf = create_sample_points(\n","            sample_points_data['coordinates'],\n","            sample_points_data['class_names']\n","        )\n","\n","    if points_gdf.empty:\n","        print(\"Nenhum ponto de amostragem criado. Finalizando.\")\n","        return pd.DataFrame(), None, gpd.GeoDataFrame()\n","\n","    print(f\"Pontos de amostragem criados: {len(points_gdf)}\")\n","    print(f\"Classes: {points_gdf['class'].unique()}\")\n","\n","    # 3. Extração EnMAP\n","    enmap_extractor = EnMAPExtractor(config)\n","    enmap_files = enmap_extractor.find_enmap_files()\n","    enmap_df = enmap_extractor.extract_enmap_signatures(points_gdf, enmap_files)\n","\n","    # 4. Análise e salvamento\n","    analyzer = SpectralAnalyzer(config)\n","    stats_summary = analyzer.generate_statistics(enmap_df)\n","    analyzer.save_results(enmap_df, stats_summary)\n","\n","    # 5. Relatório final\n","    print(\"=\" * 50)\n","    print(\"PIPELINE CONCLUÍDO!\")\n","    print(\"=\" * 50)\n","\n","    if not enmap_df.empty:\n","        print(f\"Total de assinaturas extraídas: {len(enmap_df)}\")\n","        print(f\"Arquivos salvos na pasta: {config.output_folder}\")\n","        print(f\"Classes processadas: {', '.join(enmap_df['class'].unique())}\")\n","        print(f\"Tipos de sensor: {', '.join(enmap_df['sensor_type'].unique())}\")\n","\n","        if use_systematic_grid:\n","            print(f\"Grade sistemática: {grid_spacing_km}km de espaçamento\")\n","    else:\n","        print(\"Nenhuma assinatura espectral foi extraída\")\n","\n","    print(\"=\" * 50)\n","\n","    return enmap_df, stats_summary, points_gdf\n","\n","# =============================================================================\n","# EXEMPLOS DE EXECUÇÃO\n","# =============================================================================\n","\n","if __name__ == \"__main__\":\n","    print(\"\\nEXEMPLOS DE EXECUÇÃO:\")\n","    print(\"=\" * 30)\n","\n","    print(\"\\n1. PONTOS MANUAIS:\")\n","    print(\"custom_points = {\")\n","    print(\"    'coordinates': [\")\n","    print(\"        [[-37.777, -5.111], [-37.776, -5.112]],\")\n","    print(\"        [[-39.58, -4.29], [-39.57, -4.30]]\")\n","    print(\"    ],\")\n","    print(\"    'class_names': ['Vegetacao_Densa', 'Solo_Exposto']\")\n","    print(\"}\")\n","    print(\"results_df, stats, points_gdf = main_enmap_extraction_pipeline(custom_points)\")\n","\n","    print(\"\\n2. GRADE SISTEMÁTICA:\")\n","    print(\"apa_file = '/content/drive/My Drive/APA_Chapada_Araripe.kml'\")\n","    print(\"results_df, stats, points_gdf = main_enmap_extraction_pipeline(\")\n","    print(\"    polygon_file=apa_file,\")\n","    print(\"    use_systematic_grid=True,\")\n","    print(\"    grid_spacing_km=5\")\n","    print(\")\")\n","\n","    print(\"\\n3. INTEGRAÇÃO COM SUA GRADE:\")\n","    print(\"if 'local_gdf' in locals() and not local_gdf.empty:\")\n","    print(\"    temp_file = '/content/drive/My Drive/temp_polygon.geojson'\")\n","    print(\"    local_gdf.to_file(temp_file, driver='GeoJSON')\")\n","    print(\"    results_df, stats, points_gdf = main_enmap_extraction_pipeline(\")\n","    print(\"        polygon_file=temp_file,\")\n","    print(\"        use_systematic_grid=True,\")\n","    print(\"        grid_spacing_km=5\")\n","    print(\"    )\")"],"metadata":{"id":"O3am31RlR_mb","executionInfo":{"status":"aborted","timestamp":1761499076466,"user_tz":180,"elapsed":43901,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b3630795","executionInfo":{"status":"aborted","timestamp":1761499076492,"user_tz":180,"elapsed":43920,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"source":["!pip install rasterio geopandas --quiet\n","print(\"Installed rasterio and geopandas.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6aefbe1e","executionInfo":{"status":"aborted","timestamp":1761499076494,"user_tz":180,"elapsed":43921,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"source":["# Com sua grade da APA\n","if 'local_gdf' in locals() and not local_gdf.empty:\n","    temp_file = '/content/drive/My Drive/temp_polygon.geojson'\n","    local_gdf.to_file(temp_file, driver='GeoJSON')\n","\n","    results_df, stats, points_gdf = main_enmap_extraction_pipeline(\n","        polygon_file=temp_file,\n","        use_systematic_grid=True,\n","        grid_spacing_km=5\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import glob\n","import rasterio\n","import rasterio.mask\n","import numpy as np\n","import folium\n","from folium.utilities import tempfile\n","import matplotlib.pyplot as plt # Only for temporary RGB creation if needed\n","import geopandas as gpd # Ensure geopandas is imported\n","\n","# Assuming drive_base_path and enmap_folder_name are defined\n","drive_base_path = '/content/drive/My Drive/'\n","enmap_folder_name = 'ENMAP'\n","enmap_base_path = os.path.join(drive_base_path, enmap_folder_name)\n","\n","# Assuming local_gdf (APA polygon) is available from previous steps\n","if 'local_gdf' in locals() and not local_gdf.empty:\n","    print(\"\\nProceeding to visualize EnMAP images with APA polygon overlay...\")\n","\n","    # Define patterns for Level 1B spectral images (VNIR and SWIR)\n","    spectral_image_patterns = ['*SPECTRAL_IMAGE_VNIR.TIF', '*SPECTRAL_IMAGE_SWIR.TIF']\n","\n","    enmap_l1b_spectral_files = []\n","\n","    print(f\"Searching for EnMAP Level 1B spectral image files in subdirectories within: {enmap_base_path}\")\n","\n","    try:\n","        # Walk through the base directory and its subdirectories\n","        for root, dirs, files in os.walk(enmap_base_path):\n","            for file in files:\n","                file_path = os.path.join(root, file)\n","                # Check for spectral image files\n","                for pattern in spectral_image_patterns:\n","                    if file.endswith(pattern.split('*')[-1]) and pattern.replace('*', '') in file:\n","                        enmap_l1b_spectral_files.append(file_path)\n","                        break # Found a spectral file\n","\n","\n","        print(f\"\\nFound {len(enmap_l1b_spectral_files)} EnMAP Level 1B spectral image files.\")\n","\n","        if not enmap_l1b_spectral_files:\n","            print(\"No EnMAP Level 1B spectral image files found matching patterns. Skipping visualization.\")\n","        else:\n","            # Create a Folium map centered on the APA polygon\n","            # Get the bounds of the polygon to center the map\n","            bounds = local_gdf.total_bounds\n","            center_lat = (bounds[1] + bounds[3]) / 2\n","            center_lon = (bounds[0] + bounds[2]) / 2\n","\n","            m = folium.Map(location=[center_lat, center_lon], zoom_start=9)\n","\n","            # Add the APA polygon to the map\n","            folium.GeoJson(local_gdf, name=\"APA Chapada do Araripe\").add_to(m)\n","\n","            # Add a Layer Control to toggle layers\n","            folium.LayerControl().add_to(m)\n","\n","\n","            # Process and add each EnMAP image as a raster layer\n","            processed_image_count = 0\n","            for enmap_file_path in enmap_l1b_spectral_files:\n","                 print(f\"\\nProcessing EnMAP L1B file for visualization: {os.path.basename(enmap_file_path)}\")\n","\n","                 try:\n","                     with rasterio.open(enmap_file_path) as src:\n","                         # Read the raster data and get georeferencing info\n","                         raster_data = src.read()\n","                         raster_crs = src.crs\n","                         raster_transform = src.transform\n","                         img_height, img_width = raster_data.shape[1:]\n","                         num_bands = raster_data.shape[0]\n","\n","                         print(f\"  Raster loaded. Bands: {num_bands}, Shape: {img_height}x{img_width}\")\n","                         print(f\"  CRS: {raster_crs}\")\n","\n","                         # --- Create RGB Composite for Visualization ---\n","                         # EnMAP has many bands. Select illustrative bands for RGB composite.\n","                         # Assuming bands around 650nm (Red), 550nm (Green), 450nm (Blue).\n","                         # These are illustrative indices, adjust based on actual band wavelengths if known.\n","                         # Common indices for L1B VNIR/SWIR might be different from L2A.\n","                         # Let's try generic indices that are likely within the bands.\n","\n","                         # Check if enough bands\n","                         if num_bands >= 3:\n","                              # Using illustrative indices for a false color composite\n","                              # Example: Red=NIR (~800nm), Green=Red (~650nm), Blue=Green (~550nm)\n","                              # Need to adjust indices based on EnMAP band numbers/wavelengths\n","                              # Let's use simple indices for now, assuming band 1 is first band\n","                              # Try bands that might correspond to R,G,B or a common false color:\n","                              # Assuming bands roughly correspond to:\n","                              # VNIR: Bands 1-91\n","                              # SWIR: Bands 92-224\n","                              # Let's pick bands that are likely within VNIR or SWIR ranges\n","                              # Example: Red=Band 60 (VNIR), Green=Band 30 (VNIR), Blue=Band 10 (VNIR) - adjust as needed!\n","                              # Or a false color: Red=Band 150 (SWIR), Green=Band 80 (VNIR), Blue=Band 30 (VNIR)\n","\n","                              # Check if file is VNIR or SWIR to pick appropriate bands\n","                              if 'VNIR' in os.path.basename(enmap_file_path) and num_bands >= 60:\n","                                  red_band_idx = 60 - 1 # Illustrative VNIR band\n","                                  green_band_idx = 30 - 1 # Illustrative VNIR band\n","                                  blue_band_idx = 10 - 1 # Illustrative VNIR band\n","                                  # Ensure indices are within bounds\n","                                  red_band_idx, green_band_idx, blue_band_idx = np.clip([red_band_idx, green_band_idx, blue_band_idx], 0, num_bands - 1)\n","                                  print(f\"  Using illustrative VNIR bands for RGB: {red_band_idx+1}, {green_band_idx+1}, {blue_band_idx+1}\")\n","                                  rgb_bands = [red_band_idx, green_band_idx, blue_band_idx]\n","\n","                              elif 'SWIR' in os.path.basename(enmap_file_path) and num_bands >= (150-92+1): # Assuming SWIR starts around band 92\n","                                   # Illustrative SWIR false color\n","                                   red_band_idx = 150 - 1 # Illustrative SWIR band\n","                                   green_band_idx = 80 - 1 # Illustrative VNIR band (might not be in this file if it's pure SWIR)\n","                                   blue_band_idx = 30 - 1 # Illustrative VNIR band (might not be in this file if it's pure SWIR)\n","\n","                                   # Need to handle cases where VNIR and SWIR are in separate files.\n","                                   # If this is a pure SWIR file, can't use VNIR bands.\n","                                   # Let's use simple indices for SWIR if it's a SWIR file\n","                                   if num_bands >= 3:\n","                                        red_band_idx = num_bands - 1 # Last band\n","                                        green_band_idx = num_bands // 2 # Middle band\n","                                        blue_band_idx = 0 # First band\n","                                        print(f\"  Using simple SWIR bands for RGB: {red_band_idx+1}, {green_band_idx+1}, {blue_band_idx+1}\")\n","                                        rgb_bands = [red_band_idx, green_band_idx, blue_band_idx]\n","                                   else:\n","                                        print(f\"  WARNING: Not enough bands ({num_bands}) in SWIR file for RGB composite.\")\n","                                        continue # Skip this file\n","\n","\n","                              else: # Default or not clearly VNIR/SWIR\n","                                   if num_bands >= 3:\n","                                        red_band_idx = 2 # First 3 bands\n","                                        green_band_idx = 1\n","                                        blue_band_idx = 0\n","                                        print(\"  Using first 3 bands for RGB.\")\n","                                        rgb_bands = [red_band_idx, green_band_idx, blue_band_idx]\n","                                   else:\n","                                        print(f\"  WARNING: Not enough bands ({num_bands}) for RGB composite.\")\n","                                        continue # Skip this file\n","\n","\n","                              # Read the selected bands\n","                              rgb_image_data = src.read(indexes=[b + 1 for b in rgb_bands]) # rasterio uses 1-based indexing\n","\n","                              # Transpose to (height, width, bands) for normalization/plotting\n","                              rgb_image_data = np.transpose(rgb_image_data, (1, 2, 0))\n","\n","                              # Normalize/clip values to 0-255 or 0-1 for visualization\n","                              # L1B radiance values can vary widely. Simple min/max scaling might work.\n","                              # Find min/max across all bands used for RGB\n","                              min_val = np.min(rgb_image_data)\n","                              max_val = np.max(rgb_image_data)\n","                              if max_val > min_val:\n","                                   rgb_image_normalized = (rgb_image_data - min_val) / (max_val - min_val)\n","                                   # Clip to 0-1 range\n","                                   rgb_image_normalized = np.clip(rgb_image_normalized, 0, 1)\n","                                   print(f\"  Normalized RGB values from [{min_val:.2f}, {max_val:.2f}] to [0, 1].\")\n","                              else:\n","                                   print(\"  WARNING: Min and max values are the same. Skipping normalization.\")\n","                                   rgb_image_normalized = rgb_image_data # Use raw data\n","\n","                              # Convert to uint8 (0-255) for Pillow compatibility if needed by add_child method, or keep as float 0-1\n","                              # Folium ImageOverlay can often take float 0-1\n","                              rgb_image_display = (rgb_image_normalized * 255).astype(np.uint8)\n","\n","\n","                              # --- Add Raster Overlay to Folium Map ---\n","                              # Need to get the bounds of the image in WGS84 (Lat/Lon)\n","                              # Reproject the corners of the image from raster CRS to WGS84\n","                              try:\n","                                   # Get corners in raster CRS\n","                                   corners_raster_crs = [\n","                                       rasterio.transform.xy(raster_transform, 0, 0), # Top-left\n","                                       rasterio.transform.xy(raster_transform, 0, img_width), # Top-right\n","                                       rasterio.transform.xy(raster_transform, img_height, 0), # Bottom-left\n","                                       rasterio.transform.xy(raster_transform, img_height, img_width) # Bottom-right\n","                                   ]\n","\n","                                   # Create a GeoDataFrame from corners in raster CRS\n","                                   corners_gdf_raster_crs = gpd.GeoDataFrame(\n","                                       geometry=gpd.points_from_xy([c[0] for c in corners_raster_crs], [c[1] for c in corners_raster_crs]),\n","                                       crs=raster_crs\n","                                   )\n","\n","                                   # Reproject corners to WGS84 (EPSG:4326)\n","                                   corners_gdf_wgs84 = corners_gdf_raster_crs.to_crs(epsg=4326)\n","\n","                                   # Get the bounds in WGS84\n","                                   wgs84_bounds = corners_gdf_wgs84.total_bounds\n","                                   # Folium bounds are [[south, west], [north, east]] i.e., [[ymin, xmin], [ymax, xmax]]\n","                                   folium_bounds = [[wgs84_bounds[1], wgs84_bounds[0]], [wgs84_bounds[3], wgs84_bounds[2]]]\n","                                   print(f\"  Image bounds in WGS84 for Folium: {folium_bounds}\")\n","\n","\n","                                   # Add the image overlay to the map\n","                                   # Use the normalized float image (0-1) or uint8 (0-255) - uint8 is safer\n","                                   folium.raster_layers.ImageOverlay(\n","                                       image=rgb_image_display, # Use uint8 image\n","                                       bounds=folium_bounds,\n","                                       origin='upper', # 'upper' for raster data\n","                                       name=os.path.basename(enmap_file_path).replace('.TIF', '') # Layer name\n","                                   ).add_to(m)\n","                                   print(\"  Image overlay added to map.\")\n","                                   processed_image_count += 1\n","\n","\n","                              except Exception as geo_e:\n","                                   print(f\"  ERROR reprojecting or getting bounds for Folium overlay: {geo_e}. Skipping visualization for this file.\")\n","                                   continue # Skip to next file if georeferencing fails\n","\n","\n","                         else:\n","                              print(f\"  WARNING: Not enough bands ({num_bands}) for RGB composite. Skipping visualization for this file.\")\n","                              continue # Skip this file\n","\n","                 except Exception as e:\n","                     print(f\"  ERRO loading or processing EnMAP L1B file for visualization ({os.path.basename(enmap_file_path)}): {e}\")\n","                     # Continue to the next file even if one fails\n","\n","\n","            # Display the map if at least one image was processed\n","            if processed_image_count > 0:\n","                print(\"\\nDisplaying map with EnMAP images and APA polygon overlay.\")\n","                display(m)\n","            else:\n","                print(\"\\nNo EnMAP images were successfully processed for visualization.\")\n","\n","\n","    except FileNotFoundError:\n","        print(f\"Error: The base folder '{enmap_base_path}' was not found.\")\n","        print(\"Please ensure the 'ENMAP' folder exists directly within 'My Drive' or update the 'enmap_folder_name' variable.\")\n","    except Exception as e:\n","        print(f\"An error occurred during EnMAP L1B file search or processing for visualization: {e}\")\n","\n","\n","else:\n","    print(\"\\nDataFrame 'local_gdf' (APA polygon) not found or empty. Skipping visualization.\")"],"metadata":{"id":"VhMq1sJRVs1n","executionInfo":{"status":"aborted","timestamp":1761499076495,"user_tz":180,"elapsed":43919,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instala os pacotes necessários\n","# Usamos o 'quiet' para manter o output limpo\n","!pip install spectral geopandas rasterio --quiet\n","print(\"Bibliotecas instaladas com sucesso!\")"],"metadata":{"id":"4YpgEU41ZRwd","executionInfo":{"status":"aborted","timestamp":1761499076496,"user_tz":180,"elapsed":43915,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"01bcc376","executionInfo":{"status":"aborted","timestamp":1761499076497,"user_tz":180,"elapsed":43914,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"source":["!pip install spectral"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import glob\n","import rasterio\n","import numpy as np\n","import pandas as pd\n","import geopandas as gpd\n","import spectral\n","from scipy.signal import savgol_filter\n","import matplotlib.pyplot as plt\n","\n","# Configurações de plotagem da biblioteca spectral\n","spectral.settings.show_labels = False\n","spectral.settings.show_colorbar = False\n","\n","print(\"Bibliotecas importadas e configurações realizadas.\")"],"metadata":{"id":"Vl2FRZeHZRdU","executionInfo":{"status":"aborted","timestamp":1761499076498,"user_tz":180,"elapsed":43913,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"yO4E90ZQZqCR","executionInfo":{"status":"aborted","timestamp":1761499076499,"user_tz":180,"elapsed":43911,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_enmap_scenes(base_path):\n","    \"\"\"\n","    Encontra e agrupa arquivos de cena EnMAP (VNIR, SWIR e máscaras) recursivamente.\n","\n","    Args:\n","        base_path (str): O caminho do diretório base para procurar os arquivos EnMAP.\n","\n","    Returns:\n","        list: Uma lista de dicionários, onde cada dicionário representa uma cena.\n","    \"\"\"\n","    from collections import defaultdict\n","    scenes = defaultdict(dict)\n","    search_pattern = os.path.join(base_path, '**', '*.TIF')\n","    all_files = glob.glob(search_pattern, recursive=True)\n","\n","    for f in all_files:\n","        filename = os.path.basename(f)\n","        scene_base_name = '_'.join(filename.split('_')[:4])\n","\n","        if 'SPECTRAL_IMAGE_VNIR' in filename:\n","            scenes[scene_base_name]['vnir_img'] = f\n","        elif 'SPECTRAL_IMAGE_SWIR' in filename:\n","            scenes[scene_base_name]['swir_img'] = f\n","        elif 'QL_PIXELMASK_VNIR' in filename:\n","            scenes[scene_base_name]['vnir_mask'] = f\n","        elif 'QL_PIXELMASK_SWIR' in filename:\n","            scenes[scene_base_name]['swir_mask'] = f\n","\n","    valid_scenes = [scene for scene in scenes.values() if 'vnir_img' in scene and 'swir_img' in scene]\n","    print(f\"Encontradas {len(valid_scenes)} cenas EnMAP L1B completas (VNIR+SWIR).\")\n","    return valid_scenes\n","\n","def load_enmap_scene_as_array(scene_files):\n","    \"\"\"\n","    Carrega uma cena EnMAP completa (VNIR + SWIR) como um cubo de dados NumPy,\n","    aplicando as máscaras de pixel.\n","\n","    Args:\n","        scene_files (dict): Dicionário com os caminhos para os arquivos da cena.\n","\n","    Returns:\n","        tuple: (cubo_dados, metadados) ou (None, None) em caso de falha.\n","    \"\"\"\n","    try:\n","        with rasterio.open(scene_files['vnir_img']) as vnir_src, \\\n","             rasterio.open(scene_files['swir_img']) as swir_src:\n","\n","            if vnir_src.crs != swir_src.crs or vnir_src.transform != swir_src.transform:\n","                print(f\"  AVISO: CRS ou Transform não correspondem entre VNIR e SWIR. Pulando cena.\")\n","                return None, None\n","\n","            vnir_rad = vnir_src.read()\n","            swir_rad = swir_src.read()\n","            full_radiance = np.vstack((vnir_rad, swir_rad)).astype(np.float32)\n","            metadata = vnir_src.meta.copy()\n","\n","        full_mask = None\n","        if 'vnir_mask' in scene_files and 'swir_mask' in scene_files:\n","            with rasterio.open(scene_files['vnir_mask']) as vnir_mask_src, \\\n","                 rasterio.open(scene_files['swir_mask']) as swir_mask_src:\n","                vnir_mask = vnir_mask_src.read(1)\n","                swir_mask = swir_mask_src.read(1)\n","                # Um pixel é inválido se for inválido em VNIR OU SWIR (máscara != 0)\n","                combined_mask = np.logical_or(vnir_mask != 0, swir_mask != 0)\n","                full_mask = np.broadcast_to(combined_mask, full_radiance.shape)\n","\n","        if full_mask is not None:\n","            # Aplica a máscara, substituindo pixels inválidos por NaN\n","            full_radiance[full_mask] = np.nan\n","            print(\"  Máscara de pixels VNIR+SWIR aplicada.\")\n","        else:\n","            print(\"  Nenhuma máscara de pixel encontrada ou aplicada.\")\n","\n","        # Atualiza metadados para o cubo combinado\n","        metadata.update(count=full_radiance.shape[0], dtype=str(full_radiance.dtype))\n","        return full_radiance, metadata\n","\n","    except Exception as e:\n","        print(f\"  ERRO ao carregar a cena: {e}\")\n","        return None, None\n","\n","print(\"Funções auxiliares definidas.\")"],"metadata":{"id":"kAki-F9MZubc","executionInfo":{"status":"aborted","timestamp":1761499076503,"user_tz":180,"elapsed":43913,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 1. Definir Caminhos e Carregar Dados ---\n","drive_base_path = '/content/drive/My Drive/'\n","enmap_folder_name = 'ENMAP'\n","enmap_base_path = os.path.join(drive_base_path, enmap_folder_name)\n","\n","enmap_scenes = find_enmap_scenes(enmap_base_path)\n","\n","if not enmap_scenes:\n","    print(\"Nenhuma cena EnMAP encontrada. Verifique o caminho e a estrutura de pastas.\")\n","else:\n","    # Carrega a primeira cena encontrada\n","    scene_name = os.path.basename(enmap_scenes[0]['vnir_img']).split('_ENMAP')[0]\n","    print(f\"\\\\nProcessando cena: {scene_name}\")\n","    radiance_cube, meta = load_enmap_scene_as_array(enmap_scenes[0])\n","\n","    if radiance_cube is not None:\n","        # Transpõe para o formato (linhas, colunas, bandas) que a biblioteca `spectral` usa\n","        radiance_cube = np.transpose(radiance_cube, (1, 2, 0))\n","\n","        # Remove pixels com NaN (mascarados)\n","        nan_mask = np.isnan(radiance_cube).any(axis=2)\n","        valid_pixels = radiance_cube[~nan_mask]\n","        print(f\"Dimensões do cubo de dados: {radiance_cube.shape}\")\n","        print(f\"Número de pixels válidos: {valid_pixels.shape[0]}\")\n","\n","        # --- 2. Pré-processamento ---\n","        print(\"\\\\nETAPA 2: PRÉ-PROCESSAMENTO\")\n","        hsi_smoothed = savgol_filter(valid_pixels, 11, 3, axis=1)\n","        print(\"Filtro Savitzky-Golay aplicado aos espectros.\")\n","\n","        # --- 3. Extração de Endmembers ---\n","        print(\"\\\\nETAPA 3: EXTRAÇÃO DE ENDMEMBERS\")\n","        # Estima o número de endmembers (espectros puros)\n","        num_endmembers = spectral.hysime(hsi_smoothed.T)[0]\n","        print(f\"Número de endmembers estimado (HySime): {num_endmembers}\")\n","\n","        # Encontra os pixels mais puros (PPI)\n","        ppi_indices = spectral.ppi(hsi_smoothed, num_endmembers)\n","        print(\"Índices dos pixels mais puros encontrados via PPI.\")\n","\n","        # Extrai os endmembers usando os índices do PPI como entrada para o N-FINDR\n","        endmembers = spectral.nfindr(hsi_smoothed, ppi_indices)[0]\n","        print(f\"Endmembers extraídos via N-FINDR. Dimensões: {endmembers.shape}\")\n","\n","        # --- 4. Desmistura Espectral ---\n","        print(\"\\\\nETAPA 4: DESMISTURA ESPECTRAL\")\n","        # Estima as abundâncias usando FCLS\n","        abundances = spectral.fcls(hsi_smoothed, endmembers)\n","        print(f\"Abundâncias estimadas via FCLS. Dimensões: {abundances.shape}\")\n","\n","        # --- 5. Visualização dos Resultados ---\n","        print(\"\\\\nETAPA 5: VISUALIZAÇÃO\")\n","\n","        # Plotar os endmembers extraídos\n","        plt.figure(figsize=(10, 6))\n","        for i in range(num_endmembers):\n","            plt.plot(endmembers[i], label=f'Endmember {i + 1}')\n","        plt.title('Espectros dos Endmembers Extraídos', fontsize=16)\n","        plt.xlabel('Número da Banda')\n","        plt.ylabel('Radiância (escalonada)')\n","        plt.legend()\n","        plt.grid(True)\n","        plt.show()\n","\n","        # Criar mapas de abundância\n","        abundance_maps = np.zeros((radiance_cube.shape[0] * radiance_cube.shape[1], num_endmembers))\n","        abundance_maps[~nan_mask.flatten()] = abundances\n","        abundance_maps = abundance_maps.reshape(radiance_cube.shape[0], radiance_cube.shape[1], num_endmembers)\n","\n","        # Plotar os mapas de abundância\n","        fig, axes = plt.subplots(1, num_endmembers, figsize=(5 * num_endmembers, 5))\n","        if num_endmembers == 1: axes = [axes] # Garante que `axes` seja iterável\n","        fig.suptitle('Mapas de Abundância Estimados', fontsize=16)\n","        for i, ax in enumerate(axes):\n","            im = ax.imshow(abundance_maps[:, :, i], cmap='viridis', vmin=0, vmax=1)\n","            ax.set_title(f'Endmember {i + 1}')\n","            ax.axis('off')\n","            fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","        plt.show()"],"metadata":{"id":"i2OyQhd-ZzQ0","executionInfo":{"status":"aborted","timestamp":1761499076505,"user_tz":180,"elapsed":43911,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import glob\n","import rasterio\n","import rasterio.mask\n","import numpy as np\n","import folium\n","from folium.utilities import tempfile\n","import matplotlib.pyplot as plt # Only for temporary RGB creation if needed\n","import geopandas as gpd # Ensure geopandas is imported\n","\n","# Assuming drive_base_path and enmap_folder_name are defined\n","drive_base_path = '/content/drive/My Drive/'\n","enmap_folder_name = 'ENMAP'\n","enmap_base_path = os.path.join(drive_base_path, enmap_folder_name)\n","\n","# Assuming local_gdf (APA polygon) is available from previous steps\n","if 'local_gdf' in locals() and not local_gdf.empty:\n","    print(\"\\nProceeding to visualize EnMAP images with APA polygon overlay...\")\n","\n","    # Define patterns for Level 1B spectral images (VNIR and SWIR)\n","    spectral_image_patterns = ['*SPECTRAL_IMAGE_VNIR.TIF', '*SPECTRAL_IMAGE_SWIR.TIF']\n","\n","    enmap_l1b_spectral_files = []\n","\n","    print(f\"Searching for EnMAP Level 1B spectral image files in subdirectories within: {enmap_base_path}\")\n","\n","    try:\n","        # Walk through the base directory and its subdirectories\n","        for root, dirs, files in os.walk(enmap_base_path):\n","            for file in files:\n","                file_path = os.path.join(root, file)\n","                # Check for spectral image files\n","                for pattern in spectral_image_patterns:\n","                    if file.endswith(pattern.split('*')[-1]) and pattern.replace('*', '') in file:\n","                        enmap_l1b_spectral_files.append(file_path)\n","                        break # Found a spectral file\n","\n","\n","        print(f\"\\nFound {len(enmap_l1b_spectral_files)} EnMAP Level 1B spectral image files.\")\n","\n","        if not enmap_l1b_spectral_files:\n","            print(\"No EnMAP Level 1B spectral image files found matching patterns. Skipping visualization.\")\n","        else:\n","            # Create a Folium map centered on the APA polygon\n","            # Get the bounds of the polygon to center the map\n","            bounds = local_gdf.total_bounds\n","            center_lat = (bounds[1] + bounds[3]) / 2\n","            center_lon = (bounds[0] + bounds[2]) / 2\n","\n","            m = folium.Map(location=[center_lat, center_lon], zoom_start=9)\n","\n","            # Add the APA polygon to the map\n","            folium.GeoJson(local_gdf, name=\"APA Chapada do Araripe\").add_to(m)\n","\n","            # Add a Layer Control to toggle layers\n","            folium.LayerControl().add_to(m)\n","\n","\n","            # Process and add each EnMAP image as a raster layer\n","            processed_image_count = 0\n","            for enmap_file_path in enmap_l1b_spectral_files:\n","                 print(f\"\\nProcessing EnMAP L1B file for visualization: {os.path.basename(enmap_file_path)}\")\n","\n","                 try:\n","                     with rasterio.open(enmap_file_path) as src:\n","                         # Read the raster data and get georeferencing info\n","                         raster_data = src.read()\n","                         raster_crs = src.crs\n","                         raster_transform = src.transform\n","                         img_height, img_width = raster_data.shape[1:]\n","                         num_bands = raster_data.shape[0]\n","\n","                         print(f\"  Raster loaded. Bands: {num_bands}, Shape: {img_height}x{img_width}\")\n","                         print(f\"  CRS: {raster_crs}\")\n","\n","                         # --- Create RGB Composite for Visualization ---\n","                         # EnMAP has many bands. Select illustrative bands for RGB composite.\n","                         # Assuming bands around 650nm (Red), 550nm (Green), 450nm (Blue).\n","                         # These are illustrative indices, adjust based on actual band wavelengths if known.\n","                         # Common indices for L1B VNIR/SWIR might be different from L2A.\n","                         # Let's try generic indices that are likely within the bands.\n","\n","                         # Check if enough bands\n","                         if num_bands >= 3:\n","                              # Using illustrative indices for a false color composite\n","                              # Example: Red=NIR (~800nm), Green=Red (~650nm), Blue=Green (~550nm)\n","                              # Need to adjust indices based on EnMAP band numbers/wavelengths\n","                              # Let's use simple indices for now, assuming band 1 is first band\n","                              # Try bands that might correspond to R,G,B or a common false color:\n","                              # Assuming bands roughly correspond to:\n","                              # VNIR: Bands 1-91\n","                              # SWIR: Bands 92-224\n","                              # Let's pick bands that are likely within VNIR or SWIR ranges\n","                              # Example: Red=Band 60 (VNIR), Green=Band 30 (VNIR), Blue=Band 10 (VNIR) - adjust as needed!\n","                              # Or a false color: Red=Band 150 (SWIR), Green=Band 80 (VNIR), Blue=Band 30 (VNIR)\n","\n","                              # Check if file is VNIR or SWIR to pick appropriate bands\n","                              if 'VNIR' in os.path.basename(enmap_file_path) and num_bands >= 60:\n","                                  red_band_idx = 60 - 1 # Illustrative VNIR band\n","                                  green_band_idx = 30 - 1 # Illustrative VNIR band\n","                                  blue_band_idx = 10 - 1 # Illustrative VNIR band\n","                                  # Ensure indices are within bounds\n","                                  red_band_idx, green_band_idx, blue_band_idx = np.clip([red_band_idx, green_band_idx, blue_band_idx], 0, num_bands - 1)\n","                                  print(f\"  Using illustrative VNIR bands for RGB: {red_band_idx+1}, {green_band_idx+1}, {blue_band_idx+1}\")\n","                                  rgb_bands = [red_band_idx, green_band_idx, blue_band_idx]\n","\n","                              elif 'SWIR' in os.path.basename(enmap_file_path) and num_bands >= (150-92+1): # Assuming SWIR starts around band 92\n","                                   # Illustrative SWIR false color\n","                                   red_band_idx = 150 - 1 # Illustrative SWIR band\n","                                   green_band_idx = 80 - 1 # Illustrative VNIR band (might not be in this file if it's pure SWIR)\n","                                   blue_band_idx = 30 - 1 # Illustrative VNIR band (might not be in this file if it's pure SWIR)\n","\n","                                   # Need to handle cases where VNIR and SWIR are in separate files.\n","                                   # If this is a pure SWIR file, can't use VNIR bands.\n","                                   # Let's use simple indices for SWIR if it's a SWIR file\n","                                   if num_bands >= 3:\n","                                        red_band_idx = num_bands - 1 # Last band\n","                                        green_band_idx = num_bands // 2 # Middle band\n","                                        blue_band_idx = 0 # First band\n","                                        print(f\"  Using simple SWIR bands for RGB: {red_band_idx+1}, {green_band_idx+1}, {blue_band_idx+1}\")\n","                                        rgb_bands = [red_band_idx, green_band_idx, blue_band_idx]\n","                                   else:\n","                                        print(f\"  WARNING: Not enough bands ({num_bands}) in SWIR file for RGB composite.\")\n","                                        continue # Skip this file\n","\n","\n","                              else: # Default or not clearly VNIR/SWIR\n","                                   if num_bands >= 3:\n","                                        red_band_idx = 2 # First 3 bands\n","                                        green_band_idx = 1\n","                                        blue_band_idx = 0\n","                                        print(\"  Using first 3 bands for RGB.\")\n","                                        rgb_bands = [red_band_idx, green_band_idx, blue_band_idx]\n","                                   else:\n","                                        print(f\"  WARNING: Not enough bands ({num_bands}) for RGB composite.\")\n","                                        continue # Skip this file\n","\n","\n","                              # Read the selected bands\n","                              rgb_image_data = src.read(indexes=[b + 1 for b in rgb_bands]) # rasterio uses 1-based indexing\n","\n","                              # Transpose to (height, width, bands) for normalization/plotting\n","                              rgb_image_data = np.transpose(rgb_image_data, (1, 2, 0))\n","\n","                              # Normalize/clip values to 0-255 or 0-1 for visualization\n","                              # L1B radiance values can vary widely. Simple min/max scaling might work.\n","                              # Find min/max across all bands used for RGB\n","                              min_val = np.min(rgb_image_data)\n","                              max_val = np.max(rgb_image_data)\n","                              if max_val > min_val:\n","                                   rgb_image_normalized = (rgb_image_data - min_val) / (max_val - min_val)\n","                                   # Clip to 0-1 range\n","                                   rgb_image_normalized = np.clip(rgb_image_normalized, 0, 1)\n","                                   print(f\"  Normalized RGB values from [{min_val:.2f}, {max_val:.2f}] to [0, 1].\")\n","                              else:\n","                                   print(\"  WARNING: Min and max values are the same. Skipping normalization.\")\n","                                   rgb_image_normalized = rgb_image_data # Use raw data\n","\n","                              # Convert to uint8 (0-255) for Pillow compatibility if needed by add_child method, or keep as float 0-1\n","                              # Folium ImageOverlay can often take float 0-1\n","                              rgb_image_display = (rgb_image_normalized * 255).astype(np.uint8)\n","\n","\n","                              # --- Add Raster Overlay to Folium Map ---\n","                              # Need to get the bounds of the image in WGS84 (Lat/Lon)\n","                              # Reproject the corners of the image from raster CRS to WGS84\n","                              try:\n","                                   # Get corners in raster CRS\n","                                   corners_raster_crs = [\n","                                       rasterio.transform.xy(raster_transform, 0, 0), # Top-left\n","                                       rasterio.transform.xy(raster_transform, 0, img_width), # Top-right\n","                                       rasterio.transform.xy(raster_transform, img_height, 0), # Bottom-left\n","                                       rasterio.transform.xy(raster_transform, img_height, img_width) # Bottom-right\n","                                   ]\n","\n","                                   # Create a GeoDataFrame from corners in raster CRS\n","                                   corners_gdf_raster_crs = gpd.GeoDataFrame(\n","                                       geometry=gpd.points_from_xy([c[0] for c in corners_raster_crs], [c[1] for c in corners_raster_crs]),\n","                                       crs=raster_crs\n","                                   )\n","\n","                                   # Reproject corners to WGS84 (EPSG:4326)\n","                                   corners_gdf_wgs84 = corners_gdf_raster_crs.to_crs(epsg=4326)\n","\n","                                   # Get the bounds in WGS84\n","                                   wgs84_bounds = corners_gdf_wgs84.total_bounds\n","                                   # Folium bounds are [[south, west], [north, east]] i.e., [[ymin, xmin], [ymax, xmax]]\n","                                   folium_bounds = [[wgs84_bounds[1], wgs84_bounds[0]], [wgs84_bounds[3], wgs84_bounds[2]]]\n","                                   print(f\"  Image bounds in WGS84 for Folium: {folium_bounds}\")\n","\n","\n","                                   # Add the image overlay to the map\n","                                   # Use the normalized float image (0-1) or uint8 (0-255) - uint8 is safer\n","                                   folium.raster_layers.ImageOverlay(\n","                                       image=rgb_image_display, # Use uint8 image\n","                                       bounds=folium_bounds,\n","                                       origin='upper', # 'upper' for raster data\n","                                       name=os.path.basename(enmap_file_path).replace('.TIF', '') # Layer name\n","                                   ).add_to(m)\n","                                   print(\"  Image overlay added to map.\")\n","                                   processed_image_count += 1\n","\n","\n","                              except Exception as geo_e:\n","                                   print(f\"  ERROR reprojecting or getting bounds for Folium overlay: {geo_e}. Skipping visualization for this file.\")\n","                                   continue # Skip to next file if georeferencing fails\n","\n","\n","                         else:\n","                              print(f\"  WARNING: Not enough bands ({num_bands}) for RGB composite. Skipping visualization for this file.\")\n","                              continue # Skip this file\n","\n","                 except Exception as e:\n","                     print(f\"  ERRO loading or processing EnMAP L1B file for visualization ({os.path.basename(enmap_file_path)}): {e}\")\n","                     # Continue to the next file even if one fails\n","\n","\n","            # Display the map if at least one image was processed\n","            if processed_image_count > 0:\n","                print(\"\\nDisplaying map with EnMAP images and APA polygon overlay.\")\n","                display(m)\n","            else:\n","                print(\"\\nNo EnMAP images were successfully processed for visualization.\")\n","\n","\n","    except FileNotFoundError:\n","        print(f\"Error: The base folder '{enmap_base_path}' was not found.\")\n","        print(\"Please ensure the 'ENMAP' folder exists directly within 'My Drive' or update the 'enmap_folder_name' variable.\")\n","    except Exception as e:\n","        print(f\"An error occurred during EnMAP L1B file search or processing for visualization: {e}\")\n","\n","\n","else:\n","    print(\"\\nDataFrame 'local_gdf' (APA polygon) not found or empty. Skipping visualization.\")"],"metadata":{"id":"1RrEFzfraIUq","executionInfo":{"status":"aborted","timestamp":1761499076507,"user_tz":180,"elapsed":43910,"user":{"displayName":"Vladimir Gomes","userId":"01782939318206028268"}}},"execution_count":null,"outputs":[]}]}